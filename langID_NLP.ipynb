{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "langID_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dagobert42/langID-NLP/blob/master/langID_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgCjPUC4Sk86"
      },
      "source": [
        "### Dataset Preparation\n",
        "This subsection contains methods to produce uniformly distributed chunks of our data set. From these we can then obtain n-grams of different sizes. The Wikipedia Language Identification database contains txt-files of x_train and x_test for example sentences and accordingly ordered labels in y_train, y_test.\n",
        "We read these examples and cluster them by their respective language label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt1fyVMmyyc5"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import string\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "from nltk import ngrams\r\n",
        "import collections\r\n",
        "from collections import defaultdict\r\n",
        "from collections import Counter\r\n",
        "from IPython.display import clear_output\r\n",
        "import time,math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFQqznQJjLdm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cd12cad-2d8a-4c94-e95f-1d9480d39ef4"
      },
      "source": [
        "!npx degit Dagobert42/langID-NLP/WiLI-2018_data -f"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 1 in 0.782s\n",
            "\u001b[36m> destination directory is not empty. Using --force, continuing\u001b[39m\n",
            "\u001b[36m> cloned \u001b[1mDagobert42/langID-NLP\u001b[22m#\u001b[1mmaster\u001b[22m\u001b[39m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v0_QzWx9XRU"
      },
      "source": [
        "# read data\r\n",
        "# written for the WiLI-2018 data set: https://zenodo.org/record/841984\r\n",
        "# make sure txt-files are in the specified directory when running this\r\n",
        "X_train = open('x_train.txt', encoding=\"utf8\").read().split('\\n')\r\n",
        "Y_train = open('y_train.txt', encoding=\"utf8\").read().split('\\n')\r\n",
        "X_test = open('x_test.txt', encoding=\"utf8\").read().split('\\n')\r\n",
        "Y_test = open('y_test.txt', encoding=\"utf8\").read().split('\\n')\r\n",
        "labels = pd.read_csv('labels.csv', delimiter = ';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njIRm3SO9xiV"
      },
      "source": [
        "# preprocessing the data\r\n",
        "\r\n",
        "def preprocess(X,Y):\r\n",
        "\r\n",
        "  # convert language labels to language Name => 'en' -> 'English'\r\n",
        "  lab_dict = { labels.loc[i]['Label'] : labels.loc[i]['English'] for i in range(0, len(labels)) }\r\n",
        "  y_train = [ lab_dict[item] if item != 'nan' else 'Min Nan Chinese' for item in Y ]\r\n",
        "\r\n",
        "  # remove unnecessary characters from data\r\n",
        "  extras = '!\"$%&/{}[]()=?\\\\`´*+~#-_.:,;<>|1234567890°-\\'' # Characters to remove from data\r\n",
        "  rx = '[' + re.escape(''.join(extras)) + ']'\r\n",
        "  x_train = [] \r\n",
        "  to_remove = []\r\n",
        "  i = 0\r\n",
        "  for example in X:\r\n",
        "      processed = re.sub(' +', ' ', re.sub(rx, '', example))\r\n",
        "      if(len(\"\".join(processed.split()))): # Some examples after preprocessing only contain spaces, this is a check for those examples.\r\n",
        "        x_train.append(processed)\r\n",
        "      else:\r\n",
        "        y_train.pop(i)\r\n",
        "      i+=1\r\n",
        "\r\n",
        "  return x_train,y_train\r\n",
        "\r\n",
        "# x_train = [ex1,ex2,ex3,...]\r\n",
        "# y_train = [lang_of_ex1,......]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh1WIZ_bAkZA"
      },
      "source": [
        "# sort data by language\r\n",
        "def data_by_lang(X, Y):\r\n",
        "    lang_corpora = defaultdict(list)\r\n",
        "    lang_idx = defaultdict(list)\r\n",
        "    for i in range(len(X)):\r\n",
        "        lang_corpora[Y[i]].append(X[i])\r\n",
        "        lang_idx[Y[i]].append(i)\r\n",
        "\r\n",
        "    return lang_corpora, lang_idx\r\n",
        "# lang_corpora = { 'Lang1' : [ex1,ex2,...], 'Lang2' : [ex1, ex2,,...],...}\r\n",
        "# land_idx = { 'Lang1' : [23,41,..index of example in Lang1..], 'Lang2' : [1,19,....],...}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNBMCn3bA078"
      },
      "source": [
        "# extract uniformly distributed list of examples from our data set\r\n",
        "# takes an optional argument to constrain the list of languages\r\n",
        "def get_data_chunk(X, Y, n_instances, lang_keys=[]):\r\n",
        "    _, lang_idx = data_by_lang(X, Y)\r\n",
        "    x_train = []\r\n",
        "    y_train = []\r\n",
        "    \r\n",
        "    langs = set()\r\n",
        "    if lang_keys: \r\n",
        "        langs = set(lang_keys)\r\n",
        "    else:\r\n",
        "        langs = set(Y)\r\n",
        "\r\n",
        "    for lang in langs:\r\n",
        "        indices = lang_idx[lang]\r\n",
        "        for index in range(n_instances):\r\n",
        "            x_train.append(X[indices[index]])\r\n",
        "            y_train.append(Y[indices[index]])\r\n",
        "\r\n",
        "    return x_train, y_train\r\n",
        "\r\n",
        "# x_train [ lang1_ex,lang1_ex,..n_instance_of_lang1..,lang2_ex,lang2_ex,....,...]\r\n",
        "# y_train [ lang1,lang1,....lang2,lang2,...]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_gdP0c8ZGtJ"
      },
      "source": [
        "# creating n-grams for each data entry\r\n",
        "# optional arguments:\r\n",
        "#    lang_keys - constrains the languages to use\r\n",
        "#    stepsize  - specifies the amount of characters\r\n",
        "#                to jump until the next n-gram\r\n",
        "# returns a list of n-grams\r\n",
        "#def make_n_grams(X, Y, n, stepsize=1, lang_keys=None):\r\n",
        "def make_n_grams(X, Y, n, lang_keys=[], stepsize=1):\r\n",
        "    assert stepsize >= 1\r\n",
        "    x_to_grams = []\r\n",
        "\r\n",
        "    langs = set()\r\n",
        "    if lang_keys: \r\n",
        "        langs = set(lang_keys)\r\n",
        "    else:\r\n",
        "        langs = set(Y)\r\n",
        "\r\n",
        "    for i in range(len(X)):\r\n",
        "        if Y[i] in langs:\r\n",
        "            sent = X[i]\r\n",
        "            x_to_grams.append([sent[j:j+n] for j in range(0, len(sent) - n+1, stepsize)])\r\n",
        "\r\n",
        "    return x_to_grams\r\n",
        "\r\n",
        "# x_to_grams = [[ngram_in_ex1],[ngram_in_ex2],....]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT5Bp8t6ZJyz"
      },
      "source": [
        "# counting and sorting n-grams for each language\r\n",
        "# returns a sorted dict of lang : {n-gram : count}\r\n",
        "def sort_by_tf(X, Y):\r\n",
        "    # calculating term frequency of n-grams per language\r\n",
        "    tf_per_lang = defaultdict(list)\r\n",
        "    langs = set(Y)\r\n",
        "    data, _ = data_by_lang(X, Y)\r\n",
        "    for lang,gram_list in data.items():\r\n",
        "      data[lang] = [ gram for grams in gram_list for gram in grams] # Comvert list of lists to a single list\r\n",
        "    for lang in langs:\r\n",
        "        tf_per_lang[lang] = dict(\r\n",
        "            zip(list(Counter(data[lang]).keys()),\r\n",
        "                 list(Counter(data[lang]).values())))\r\n",
        "\r\n",
        "    # sort by term frequency\r\n",
        "    sorted_tf_per_lang = defaultdict(list)\r\n",
        "    for lang in langs:\r\n",
        "        sorted_tf_per_lang[lang] = { word : value for word, value in sorted(tf_per_lang[lang].items(), key=lambda item:item[1], reverse=True) }\r\n",
        "    \r\n",
        "    return sorted_tf_per_lang\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG3cYY3GVpMy"
      },
      "source": [
        "### Understanding Data\n",
        "In the following we review some examples to get an understanding of our data...\n",
        "Particularly interesting are languages with a degree of similarity. Here we print examples of languages that use the latin alphabet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUM_YDQ4dqkD"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def make_barplots(n_gram_size, lang_key, commoncollect, base_counts, compare_counts, otherlangs, concise=True):\n",
        "    width = 0.35  # the width of the bars\n",
        "    if len(otherlangs) > 6 and concise==False:\n",
        "        nrows = 3\n",
        "        ncols = 3\n",
        "        figsize=(22, 10)\n",
        "    elif len(otherlangs) > 4 and concise==False:\n",
        "        nrows = 2\n",
        "        ncols = 3\n",
        "        figsize=(22, 10)\n",
        "    elif len(otherlangs) > 1 and concise==False:\n",
        "        nrows = 1\n",
        "        ncols = len(otherlangs)\n",
        "        if len(otherlangs) == 4:\n",
        "            figsize=(26, 5)\n",
        "        else:\n",
        "            figsize=(18, 4)\n",
        "    elif len(otherlangs) == 1 or concise==True:\n",
        "        try:\n",
        "            fig, ax = plt.subplots(figsize=(7, 4))\n",
        "            fig.suptitle('Frequency of %s-grams in %s compared to %s:' % (n_gram_size, lang_key, otherlangs[0]),  fontsize=16)\n",
        "            x = np.arange(len(commoncollect[0]))  # the label locations   \n",
        "            rects1 = ax.bar(x - width/2, base_counts[0], width, color = 'r', label=lang_key)\n",
        "            rects2 = ax.bar(x + width/2, compare_counts[0], width, color = 'g', label=otherlangs[0])\n",
        "            ax.set_xticks(x)\n",
        "            ax.set_xticklabels(commoncollect[0], fontsize=14)\n",
        "            ax.legend(fontsize=12)\n",
        "            plt.show()\n",
        "        except IndexError:\n",
        "            print('there was an IndexError')\n",
        "            return\n",
        "        return\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, sharey = 'row', figsize=figsize)\n",
        "    fig.suptitle('Frequency of %s-grams in %s compared to other languages:' % (n_gram_size, lang_key),  fontsize=20)\n",
        "    for ax, common_ngrams, counts_langkey, counts_otherlang, otherlang in zip(axes.flatten(), commoncollect, base_counts, compare_counts, otherlangs):\n",
        "        x = np.arange(len(common_ngrams)) \n",
        "        rects1 = ax.bar(x - width/2, counts_langkey, width, color = 'r', label=lang_key)\n",
        "        rects2 = ax.bar(x + width/2, counts_otherlang, width, color = 'g', label=otherlang)\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(common_ngrams, fontsize=14)\n",
        "        ax.legend(fontsize=12)\n",
        "        \n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC_uPl7fMbOf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "ceba92cc-df7e-4029-eeaa-7c29470d9a1c"
      },
      "source": [
        "'''\n",
        "\n",
        "x_train, y_train = preprocess(X_train[:-1],Y_train[:-1])\n",
        "\n",
        "latin_languages = ['German', 'English', 'French', 'Spanish', 'Italian', 'Portuguese', \n",
        "                    'Estonian', 'Turkish', 'Romanian', 'Swedish', 'Latin', 'Dutch']\n",
        "                    \n",
        "# produces charts of counts of common n-grams in different languages, and tables suggesting similar languages based on these\n",
        "\n",
        "for n_gram_size in range(4,7):\n",
        "    m_samples = 20\n",
        "\n",
        "    ng_related = {}\n",
        "    \n",
        "    x_train_grams = make_n_grams(x_train, y_train, n_gram_size, stepsize = n_gram_size)\n",
        "    sorted_tf_per_lang = sort_by_tf(x_train_grams, y_train)\n",
        "\n",
        "    for lang_key in latin_languages:\n",
        "\n",
        "        ng_related[lang_key] = []\n",
        "        latin_languages.remove(lang_key)\n",
        "        latin_langs = latin_languages\n",
        "        top_m = list(sorted_tf_per_lang[lang_key].keys())[:m_samples]\n",
        "\n",
        "        commoncollect, base_counts, compare_counts, otherlangs = [], [], [], []\n",
        "\n",
        "        for otherlang in latin_langs:\n",
        "            top_m_x = list(sorted_tf_per_lang[otherlang].keys())[:m_samples]\n",
        "            common_ngrams = list(set(top_m).intersection(top_m_x))\n",
        "            \n",
        "            if len(common_ngrams) > 2:\n",
        "                \n",
        "                ng_related[lang_key].append(otherlang)\n",
        "                \n",
        "                # get counts of the entries in common_ngrams for each language.\n",
        "                # These are stored as the values corresponding to the n-gram keys in the dictionary\n",
        "                counts_langkey = []\n",
        "                counts_otherlang = []\n",
        "                for i in common_ngrams:\n",
        "                    counts_langkey.append(sorted_tf_per_lang[lang_key][i])\n",
        "                    counts_otherlang.append(sorted_tf_per_lang[otherlang][i])\n",
        "\n",
        "                common_ngrams = [k.replace(' ', '_') for k in common_ngrams]\n",
        "                \n",
        "                #print(lang_key, \"and\", otherlang, \"have the following frequent\", n_gram_size,\"-grams in common:\",common_ngrams)\n",
        "                #print('\\n ')\n",
        "\n",
        "                commoncollect.append(common_ngrams)\n",
        "                base_counts.append(counts_langkey)\n",
        "                compare_counts.append(counts_otherlang)\n",
        "                otherlangs.append(otherlang)\n",
        "\n",
        "        if commoncollect:\n",
        "        # this sorting operation is to position the largest n-gram intersections at the top of the lists.\n",
        "            commoncollect, base_counts, compare_counts, otherlangs = zip(*sorted(zip(commoncollect, base_counts, compare_counts, otherlangs), key=lambda x: len(x[0]), reverse=True))\n",
        " \n",
        "            # set parameter \"concise\" to False if you want an extensive set of bar charts in the output\n",
        "            make_barplots(n_gram_size, lang_key, commoncollect, \n",
        "                          base_counts, compare_counts, otherlangs, concise=True)\n",
        "        \n",
        "        latin_languages = ['German', 'English', 'French', 'Spanish', 'Italian', 'Portuguese', \n",
        "                           'Estonian', 'Turkish', 'Romanian', 'Swedish', 'Latin', 'Dutch']                    \n",
        "    \n",
        "    print('similar languages based on ', n_gram_size, '- grams:')\n",
        "    for key, val in ng_related.items():\n",
        "        print(key, ':', val)\n",
        "    \n",
        "    print('\\n ')\n",
        "\n",
        "time.sleep(120)\n",
        "clear_output()\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nx_train, y_train = preprocess(X_train[:-1],Y_train[:-1])\\n\\nlang_corpora, _ = data_by_lang(x_train, y_train)\\n\\nlatin_languages = [\\'German\\', \\'English\\', \\'French\\', \\'Spanish\\', \\'Italian\\', \\'Portuguese\\', \\n                    \\'Estonian\\', \\'Turkish\\', \\'Romanian\\', \\'Swedish\\', \\'Latin\\', \\'Dutch\\']\\n                    \\n# produces charts of counts of common n-grams in different languages, and tables suggesting similar languages based on these\\n\\nfor n_gram_size in range(3,6):\\n    m_samples = 20\\n\\n    ng_related = {}\\n    \\n    x_train_grams = make_n_grams(x_train, y_train, n_gram_size, stepsize = n_gram_size - 1)\\n    sorted_tf_per_lang = sort_by_tf(x_train_grams, y_train)\\n\\n    for lang_key in latin_languages:\\n        latin_languages = [\\'German\\', \\'English\\', \\'French\\', \\'Spanish\\', \\'Italian\\', \\'Portuguese\\', \\n                           \\'Estonian\\', \\'Turkish\\', \\'Romanian\\', \\'Swedish\\', \\'Latin\\', \\'Dutch\\']\\n        ng_related[lang_key] = []\\n        latin_languages.remove(lang_key)\\n        latin_langs = latin_languages\\n        top_m = list(sorted_tf_per_lang[lang_key].keys())[:m_samples]\\n\\n        commoncollect, base_counts, compare_counts, otherlangs = [], [], [], []\\n\\n        for otherlang in latin_langs:\\n            top_m_x = list(sorted_tf_per_lang[otherlang].keys())[:m_samples]\\n            common_ngrams = list(set(top_m).intersection(top_m_x))\\n            \\n            if len(common_ngrams) > 1:\\n                \\n                #print(lang_key, \"and\", otherlang, \"have the following frequent\", n_gram_size,\"-grams in common:\",common_ngrams)\\n                #print(\\'\\n \\')\\n                ng_related[lang_key].append(otherlang)\\n                \\n                # get counts of the entries in common_ngrams for each language.\\n                # These are stored as the values corresponding to the n-gram keys in the dictionary\\n                counts_langkey = []\\n                counts_otherlang = []\\n                for i in common_ngrams:\\n                    counts_langkey.append(sorted_tf_per_lang[lang_key][i])\\n                    counts_otherlang.append(sorted_tf_per_lang[otherlang][i])\\n\\n                common_ngrams = [k.replace(\\' \\', \\'_\\') for k in common_ngrams]\\n                \\n                commoncollect.append(common_ngrams)\\n                base_counts.append(counts_langkey)\\n                compare_counts.append(counts_otherlang)\\n                otherlangs.append(otherlang)\\n        \\n        # this sorting action is to put the largest n-gram intersections at the top of the lists.\\n        commoncollect, base_counts, compare_counts = zip(*sorted(zip(commoncollect, base_counts, compare_counts), key=lambda x: len(x[0]), reverse=True))\\n\\n        if len(otherlangs) > 0:\\n          make_barplots(n_gram_size, lang_key, commoncollect, base_counts, compare_counts, otherlangs)\\n                    \\n    print(\\'similar languages based on \\', n_gram_size, \\'- grams:\\')\\n    for key, val in ng_related.items():\\n        print(key, \\':\\', val)\\n    \\n    print(\\'\\n \\')\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3vFh28hYXfA"
      },
      "source": [
        "### Naive Bayes Classifier\n",
        "To obtain a baseline for the language identification task we employ a simple Naive Bayes classifier. Our first step is to collect the top n-grams into feature matrices..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlUCSGN9Wg3l"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import time,math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07I5K2SxKXWF"
      },
      "source": [
        "def time_since(since):\r\n",
        "    s = time.time() - since\r\n",
        "    m = math.floor(s / 60)\r\n",
        "    s -= m * 60\r\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stiyBC09ePY0"
      },
      "source": [
        "# extracts lists of top n frequent n-grams from data\r\n",
        "def get_top_n_features(X_grams, Y, n_features):\r\n",
        "  '''\r\n",
        "  X : [[ngram_in_ex1],[ngram_in_ex2],....]\r\n",
        "  Y : ['lang1','lang1',...,'lang2',...]\r\n",
        "  n_features : number of ngram to pick from each language\r\n",
        "  '''\r\n",
        "  sorted_freq_per_lang = sort_by_tf(X_grams, Y)\r\n",
        "  features = []\r\n",
        "  for lang, grams_dict in sorted_freq_per_lang.items():\r\n",
        "      i = 0\r\n",
        "      for gram, count in grams_dict.items():\r\n",
        "          if i <= n_features:\r\n",
        "              features.append(gram)\r\n",
        "          else:\r\n",
        "              break\r\n",
        "          i += 1\r\n",
        "      \r\n",
        "  return list(set(features))\r\n",
        "\r\n",
        "# features : ['and','he ','öä ',....] Top ngrams from corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUr77bPVeVQm"
      },
      "source": [
        "# convert data to feature matrix\r\n",
        "def create_feature_matrix(X, features):\r\n",
        "  '''\r\n",
        "  X : [[ngram_in_ex1],[ngram_in_ex2],....]\r\n",
        "  features : ['and','he ','öä ',....] Top ngrams from corpus\r\n",
        "\r\n",
        "  '''\r\n",
        "  mat = np.zeros((len(X),len(features)))\r\n",
        "  i = 0\r\n",
        "  for gram_list in X:\r\n",
        "      gram_count = []\r\n",
        "      for gram in features:          \r\n",
        "          if gram in gram_list:\r\n",
        "              gram_count.append(gram_list.count(gram)+1)\r\n",
        "          else:\r\n",
        "              gram_count.append(1)\r\n",
        "      mat[i] = gram_count\r\n",
        "      i+=1\r\n",
        "\r\n",
        "  return mat\r\n",
        "  # mat : array([[4,1,2,1,...],[1,1,1,2,3,1,...],...])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaeJeeEvRtDd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "47679370-2022-4a89-d3a1-576f9f883fb4"
      },
      "source": [
        "'''\r\n",
        "n_instances = 100 # instance per language\r\n",
        "n_gram_size = 5\r\n",
        "n_features = 10 # features per language\r\n",
        "start = time.time()\r\n",
        "print(\"Starting preprocessing at {} ..\".format(time_since(start)))\r\n",
        "\r\n",
        "x_train, y_train = preprocess(X_train[:-1], Y_train[:-1])\r\n",
        "\r\n",
        "print(\"Preprocessing Done at {}.\".format(time_since(start)))\r\n",
        "\r\n",
        "# reduce languages to get smaller data subset\r\n",
        "x_train, y_train = get_data_chunk(x_train, y_train, n_instances)\r\n",
        "\r\n",
        "print(\"Making ngrams at {} ..\".format(time_since(start)))\r\n",
        "x_train_grams = make_n_grams(x_train, y_train, n_gram_size)\r\n",
        "\r\n",
        "print('Extracting features at {} ...'.format(time_since(start)))\r\n",
        "# create features for dataset\r\n",
        "features = get_top_n_features(x_train_grams, y_train, n_features)\r\n",
        "\r\n",
        "print('Creating feature matrix at {}  ....'.format(time_since(start)))\r\n",
        "# convert dataset into feature matrix\r\n",
        "feature_matrix = create_feature_matrix(x_train_grams, features)\r\n",
        "print('Data Preperation completed after {}'.format(time_since(start)))\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nn_instances = 100 # instance per language\\nn_gram_size = 5\\nn_features = 10 # features per language\\nstart = time.time()\\nprint(\"Starting preprocessing at {} ..\".format(time_since(start)))\\n\\nx_train, y_train = preprocess(X_train[:-1], Y_train[:-1])\\n\\nprint(\"Preprocessing Done at {}.\".format(time_since(start)))\\n\\n# reduce languages to get smaller data subset\\nx_train, y_train = get_data_chunk(x_train, y_train, n_instances)\\n\\nprint(\"Making ngrams at {} ..\".format(time_since(start)))\\nx_train_grams = make_n_grams(x_train, y_train, n_gram_size)\\n\\nprint(\\'Extracting features at {} ...\\'.format(time_since(start)))\\n# create features for dataset\\nfeatures = get_top_n_features(x_train_grams, y_train, n_features)\\n\\nprint(\\'Creating feature matrix at {}  ....\\'.format(time_since(start)))\\n# convert dataset into feature matrix\\nfeature_matrix = create_feature_matrix(x_train_grams, features)\\nprint(\\'Data Preperation completed after {}\\'.format(time_since(start)))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsIdn1iIRu2g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "67e936ba-cd6d-4c83-bef2-f30a9b71f330"
      },
      "source": [
        "'''\r\n",
        "# Gaussian Naive Bayes Model Training\r\n",
        "encoder = LabelEncoder()\r\n",
        "X = feature_matrix\r\n",
        "Y = encoder.fit_transform(y_train)\r\n",
        "model = GaussianNB()\r\n",
        "model.fit(X,Y)\r\n",
        "'''\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Gaussian Naive Bayes Model Training\\nencoder = LabelEncoder()\\nX = feature_matrix\\nY = encoder.fit_transform(y_train)\\nmodel = GaussianNB()\\nmodel.fit(X,Y)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjTptZN9Rxxl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "outputId": "6a56da22-5f88-4972-8ada-450b4cfafd35"
      },
      "source": [
        "'''\r\n",
        "# model testing\r\n",
        "start = time.time()\r\n",
        "print('Test Data preperation starting ...')\r\n",
        "x,y = preprocess(X_test[:20000], Y_test[:20000])\r\n",
        "\r\n",
        "print(\"Making ngrams at {} ..\".format(time_since(start)))\r\n",
        "x_test_grams = make_n_grams(x, y, n_gram_size)\r\n",
        "\r\n",
        "print('Creating feature matrix at {}  ....'.format(time_since(start)))\r\n",
        "x = create_feature_matrix(x_test_grams, features)\r\n",
        "\r\n",
        "print('Test Data Preperation completed after {}'.format(time_since(start)))\r\n",
        "\r\n",
        "y = encoder.fit_transform(y)\r\n",
        "y_pred = model.predict(x)\r\n",
        "conf_matrix = confusion_matrix(y_pred=y_pred, y_true=y)\r\n",
        "acc = round(accuracy_score(y_pred=y_pred, y_true=y), 4) * 100\r\n",
        "print(f\"Accuracy is {acc}%\")\r\n",
        "'''\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# model testing\\nstart = time.time()\\nprint(\\'Test Data preperation starting ...\\')\\nx,y = preprocess(X_test[:20000], Y_test[:20000])\\n\\nprint(\"Making ngrams at {} ..\".format(time_since(start)))\\nx_test_grams = make_n_grams(x, y, n_gram_size)\\n\\nprint(\\'Creating feature matrix at {}  ....\\'.format(time_since(start)))\\nx = create_feature_matrix(x_test_grams, features)\\n\\nprint(\\'Test Data Preperation completed after {}\\'.format(time_since(start)))\\n\\ny = encoder.fit_transform(y)\\ny_pred = model.predict(x)\\nconf_matrix = confusion_matrix(y_pred=y_pred, y_true=y)\\nacc = round(accuracy_score(y_pred=y_pred, y_true=y), 4) * 100\\nprint(f\"Accuracy is {acc}%\")\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppf3M1lWS9BS"
      },
      "source": [
        "# Model                Instance_per_language   N_gram       Features_per_language         Accuracy             Test_Instance\r\n",
        "# GaussianNB              150                     3                   40                     79%                   20k\r\n",
        "# GaussianNB              150                     4                   40                     87%                   20k\r\n",
        "# GaussianNB              150                     5                   40                     87%                   25k\r\n",
        "# GaussianNB              200                     5                   30                     85%                   25k\r\n",
        "# MultinomialNB           150                     3                   40                     77%                   25k  \r\n",
        "# MultinomialNB           150                     4                   40                     73%                   25k  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC1mI32qeqY8"
      },
      "source": [
        "### RNN Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3fZ8Vrmd5hi"
      },
      "source": [
        "import torch\r\n",
        "import time\r\n",
        "from torch.autograd import Variable \r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E74Oh7drBg4-"
      },
      "source": [
        "# helper to print progress bars of this length\n",
        "bar_len = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmHu-KycMevY"
      },
      "source": [
        "**CHANGE TO GPU MODE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXFTaWPSMdqO"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPUswhM1qH8X"
      },
      "source": [
        "class RNN(nn.Module):\r\n",
        "    def __init__(self, input_size, hid_size, output_size, layers, embedding):\r\n",
        "\r\n",
        "        super(RNN, self).__init__()\r\n",
        "        self.hidden_dim = hid_size\r\n",
        "        self.layers = layers\r\n",
        "        self.embedding_size = embedding \r\n",
        "        self.dropout = nn.Dropout(0.4)\r\n",
        "        self.input_size = input_size\r\n",
        "        self.output_size = output_size\r\n",
        "        self.embeddings = nn.Embedding(self.input_size,self.embedding_size)\r\n",
        "        self.rnn = nn.GRU(input_size=self.embedding_size,hidden_size=self.hidden_dim,num_layers = self.layers)\r\n",
        "        self.linear = nn.Linear(self.hidden_dim,self.output_size)\r\n",
        "\r\n",
        "    \r\n",
        "    def forward(self, x):\r\n",
        "        # x : B x S where B is batch size and S is sequence size\r\n",
        "        # Sequence size is length of one ngram vector encoding\r\n",
        "        batch_size = x.size(0) \r\n",
        "        x = x.t() \r\n",
        "        embedded = self.embeddings(x) # S x B x I , here I is input_size/vocab size\r\n",
        "        hidden = self._init_hidden(batch_size)\r\n",
        "        output,hidden = self.rnn(embedded,hidden)\r\n",
        "        output = self.dropout(output) \r\n",
        "        fc_output = self.linear(output[-1]) # B x L , L is number of classes/languages\r\n",
        "        return fc_output\r\n",
        "\r\n",
        "    def _init_hidden(self,batch_size):\r\n",
        "        hidden_state = torch.zeros(self.layers,batch_size, self.hidden_dim, device=device)\r\n",
        "        return hidden_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ennmQVVXqfI4"
      },
      "source": [
        "def padding(vector_inps, lengths):\r\n",
        "    '''\r\n",
        "    This function takes variable lengths vectors and convert them into equal length by padding 0\r\n",
        "    Input : \"vector_inps\" list of vectors containing indices of ngrams\r\n",
        "            \"lengths \" length of each vector\r\n",
        "    Output : tensor containing vectors of equal length after padding. This length is equal to maximum number(M) in list of \"lengths\".\r\n",
        "    '''\r\n",
        "    inp_tensor = torch.zeros((len(vector_inps),lengths.max()), device= device).long()\r\n",
        "    for idx, (seq, seq_len) in enumerate(zip(vector_inps,lengths)):\r\n",
        "        inp_tensor[idx, :seq_len] = torch.LongTensor(seq)\r\n",
        "    return inp_tensor\r\n",
        "\r\n",
        "    # inp_tensor : tensor([[12,342,...,0],[56,2311,....],....])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU5wFzymqguQ"
      },
      "source": [
        "def train(decoder, criterion, decoder_optimizer, inp, target, batch = 100):\r\n",
        "    '''\r\n",
        "    decoder : Model\r\n",
        "    inp  : tensor([[12,342,...,0],[56,2311,....],....]) Example encodings\r\n",
        "    target : tensor([41,127,234,16,....]) Label Encodings\r\n",
        "    '''\r\n",
        "    decoder.zero_grad()\r\n",
        "    loss = 0\r\n",
        "    for i in range(1,int(len(inp)/batch)):\r\n",
        "        # input to model should be in form B x S where B is batch size and S is sequence size\r\n",
        "        output = decoder(inp[(i-1) * batch: (i) * batch].view(batch, -1))\r\n",
        "        loss += criterion(output, target[(i-1)*batch:(i)*batch])\r\n",
        "    loss.backward()\r\n",
        "    decoder_optimizer.step()\r\n",
        "\r\n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRlIup7rK5RY"
      },
      "source": [
        "def create_encodings(X_grams, Y, word_to_ix):\r\n",
        "    '''\r\n",
        "    X_grams : [[ngram_in_ex1],[ngram_in_ex2],....]\r\n",
        "    Y : ['lang1','lang1',...,'lang2',....]\r\n",
        "    word_to_ix : {' of':1,'apf':2,....} This is vocabulary of selected top ngrams\r\n",
        "    '''\r\n",
        "    x_grams = []\r\n",
        "    y_grams = []\r\n",
        "    gram_len = []\r\n",
        "    iter = len(X_grams)/10\r\n",
        "    print('Creating Encoding for X')\r\n",
        "    for j in range(len(X_grams)):\r\n",
        "        gramlist = X_grams[j] # list of ngrams in example j\r\n",
        "        gramlist = list(dict.fromkeys(sorted(gramlist,key=gramlist.count,reverse=True)))\r\n",
        "        grams = [word_to_ix[w] for w in gramlist if w in list(word_to_ix.keys()) ] \r\n",
        "        \r\n",
        "        if (len(grams) >= 1): # resulting grams list must not be empty\r\n",
        "            x_grams.append(grams) # Add encodings to x_grams\r\n",
        "            gram_len.append(len(grams)) # Add corresponding data\r\n",
        "            y_grams.append(Y[j])\r\n",
        "\r\n",
        "        if (j % iter == 0):\r\n",
        "            print('\\r{}% data prepared at time {}'.format((j/len(X_grams))*100, time_since(start)), end=' ')\r\n",
        "    \r\n",
        "    print('\\r{}% data prepared at time {}'.format(100, time_since(start)), end=' ')\r\n",
        "    gram_len = torch.LongTensor(gram_len)\r\n",
        "    inp = padding(x_grams,gram_len)\r\n",
        "\r\n",
        "    print('\\nCreating Encoding for Y')\r\n",
        "    label = list(set(y_grams))\r\n",
        "    labels_to_idx = { lang:i  for i,lang in enumerate(label)}\r\n",
        "    y_label = torch.zeros(len(y_grams),device=device).long()\r\n",
        "    for i in range(len(y_label)):\r\n",
        "        y_label[i] = labels_to_idx[y_grams[i]]\r\n",
        "    target = Variable(torch.cuda.LongTensor(y_label))\r\n",
        "    return inp, target\r\n",
        "\r\n",
        "  # inp  : tensor([[12,342,...,0],[56,2311,....],....])\r\n",
        "  # target : tensor([41,127,234,16,....])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlTIy_zRkxNE"
      },
      "source": [
        "def prepare_data(X, Y, n_samples, n_gram_size, n_features, lang_keys=[]):\r\n",
        "    '''\r\n",
        "    Data is prepared in 3 steps:\r\n",
        "    1. ngram is created from given dataset i.e each example is converted into a list of ngram\r\n",
        "    2. These ngrams are used to create vocabulary\r\n",
        "    3. Finally dataset is converted into encodings to feed into RNN\r\n",
        "    '''\r\n",
        "\r\n",
        "    # reduce languages to get smaller data subset\r\n",
        "    x_train, y_train = get_data_chunk(X, Y, n_samples, lang_keys)\r\n",
        "\r\n",
        "    print(\"Making n-grams at {} ..\".format(time_since(start)), 'of size: ', n_gram_size)\r\n",
        "    x_train_grams = make_n_grams(x_train, y_train, n_gram_size, lang_keys)\r\n",
        "\r\n",
        "    # create features for dataset\r\n",
        "    print('Extracting', n_features, 'features at {} ...'.format(time_since(start)))\r\n",
        "    features = get_top_n_features(x_train_grams, y_train, n_features)\r\n",
        "    word_to_ix = {word: i for i, word in enumerate(features)}\r\n",
        "\r\n",
        "    inp, target = create_encodings(x_train_grams, y_train, word_to_ix)\r\n",
        "    return word_to_ix, inp, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snUkxMh3vGjJ"
      },
      "source": [
        "def start_training(X, Y, input_size, hidden_size, n_layers, embedding_size, lr, batch, n_epochs):\r\n",
        "    output_size = len(set(Y.cpu().numpy())) # number of languages\r\n",
        "    model = RNN(input_size, hidden_size, output_size, n_layers, embedding_size).to(device)\r\n",
        "    decoder_optimizer = torch.optim.Adam(model.parameters(), lr=lr)\r\n",
        "    criterion = nn.CrossEntropyLoss()\r\n",
        "    print_every = n_epochs/10\r\n",
        "    all_losses = []\r\n",
        "    for epoch in range(1, n_epochs+1):\r\n",
        "        loss = train(model, criterion, decoder_optimizer, X, target, batch)\r\n",
        "        all_losses.append(loss)\r\n",
        "        if(epoch % print_every == 0):\r\n",
        "            i = math.ceil(epoch/n_epochs * bar_len)\r\n",
        "            print('\\r', '#' * i, ' ' * (bar_len-i), epoch/n_epochs * 100, '%',\r\n",
        "                  '[{} epoch: {} loss: {:.4f}]'.format(time_since(start), epoch, loss), end=' ')\r\n",
        "        \r\n",
        "    print(\"\\nTraining Complete.\")\r\n",
        "    return model, all_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz039G3cLEFB"
      },
      "source": [
        "def predict(model, test_x, test_y):\r\n",
        "    '''\r\n",
        "    decoder : Model\r\n",
        "    test_x  : tensor([[12,342,...,0],[56,2311,....],....]) Example encodings\r\n",
        "    true : tensor([41,127,234,16,....]) Label Encodings\r\n",
        "\r\n",
        "    '''\r\n",
        "    out = model(test_x) # out : B x L, where B is batch size and L is number of Labels/Classes\r\n",
        "    out = out.argmax(dim=1)\r\n",
        "    correct = out.eq(test_y.data.view_as(out)).cpu().sum()\r\n",
        "    conf_matrix = confusion_matrix(y_pred=out.cpu().numpy(),y_true=test_y.cpu().numpy())\r\n",
        "    accuracy = (correct/len(test_x))*100\r\n",
        "    print(\"Accuracy is {}%\".format(accuracy))\r\n",
        "\r\n",
        "    # code for heatmaps:\r\n",
        "    group_counts = [\"{0:0.0f}\\n\".format(value) for value in conf_matrix.flatten()]\r\n",
        "    # we want percentages to show % of predictions in each true cell, which means the the sums should be done by row\r\n",
        "    group_percentages = [\"{0:.2%}\".format(value) for value in (conf_matrix/conf_matrix.sum(axis=1)).flatten()]\r\n",
        "    box_labels = [f\"{v1}{v2}\".strip() for v1, v2 in zip(group_counts, group_percentages)]    \r\n",
        "    box_labels = np.asarray(box_labels).reshape(conf_matrix.shape[0], conf_matrix.shape[1])\r\n",
        "    plt.subplots(figsize=(10,10))\r\n",
        "    # PROBLEM: I have hard-coded the language group as the tick labels - ideally this should be fixed.\r\n",
        "    sns.heatmap(conf_matrix, cmap='coolwarm', annot=box_labels, fmt=\"\", linewidths=1.5, xticklabels=dsl_groups_ABC, yticklabels=dsl_groups_ABC)\r\n",
        "    plt.xlabel(\"Predicted Language Label\")\r\n",
        "    plt.ylabel(\"True Language Label\")\r\n",
        "    plt.show()\r\n",
        "    \r\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQkFVzOlLFrS"
      },
      "source": [
        "def test_model(model, x_test, y_test, n_gram_size, vocab): \r\n",
        "    start = time.time()\r\n",
        " \r\n",
        "    print('Making n-grams for Test Data of size: ', n_gram_size, 'at {} ..'.format(time_since(start)))\r\n",
        "    x_test_grams = make_n_grams(x_test, y_test, n_gram_size)\r\n",
        " \r\n",
        "    print('Preparing encoding for Test Data at {}'.format(time_since(start))) \r\n",
        "    inp_t, true = create_encodings(x_test_grams, y_test, vocab) \r\n",
        "    print('Encoding completed at {}'.format(time_since(start))) \r\n",
        " \r\n",
        "    return predict(model, inp_t, true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFcw6M_hD5KL"
      },
      "source": [
        "Because of memory we have to train with smaller subsets of languages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KthCnHfMn5lF"
      },
      "source": [
        "# languages with different scripts or alphabets\n",
        "diff_alph_langs = ['Arabic', 'Russian', 'Cherokee', 'Central Khmer', 'Standard Chinese', 'Japanese', \n",
        "                   'Modern Greek', 'Hebrew', 'English']\n",
        "\n",
        "# languages from different families (https://glottolog.org/glottolog/family)\n",
        "diff_fam_langs = ['Afrikaans', 'Albanian', 'Cherokee', 'Javanese', 'Hungarian', 'Turkish', \n",
        "                   'Japanese', 'Arabic', 'English']\n",
        "\n",
        "######### similar language sets\n",
        "# Latin-alphabet languages with similar 4-grams\n",
        "latin_4_grams = ['French', 'English', 'Italian', 'Portuguese', 'Estonian',\n",
        "                 'Turkish', 'Romanian', 'Swedish', 'Latin', 'Dutch']\n",
        "\n",
        "# groups of similar languages from the DSL benchmark\n",
        "dsl_groups_ABC = ['Bosnian', 'Croatian', 'Serbian', 'Indonesian', 'Malay', 'Czech', 'Slovak']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NTq9-KewZwg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9050a112-09c7-43c6-9404-db821c6f0923"
      },
      "source": [
        "# Single NGRAM as Feature\n",
        "n_gram_list = [7, 8]\n",
        "n_instances = [200, 75]\n",
        "n_features = [7, 10, 15]\n",
        "acuuracy_list = []\n",
        "loss_list = []\n",
        "\n",
        "hidden_list = [32, 64, 128, 256]\n",
        "n_layers_list = [1, 2, 3, 4]\n",
        "embedding_list = [32, 64, 128, 256]\n",
        "lr_list = [0.001, 0.005, 0.01, 0.05, 0.1,0.5]\n",
        "epoch_list = [100, 500, 1000, 3000, 5000]\n",
        "\n",
        "X_Train, Y_Train = preprocess(X_train[:-1], Y_train[:-1])\n",
        "X_Test, Y_Test = preprocess(X_test[:-1], Y_test[:-1])\n",
        "models = []\n",
        "all_losses = []\n",
        "all_accuracies = []\n",
        "\n",
        "for n_instance in n_instances:\n",
        "    for n_feature in n_features:\n",
        "        for n_gram_size in n_gram_list:\n",
        "            start = time.time()\n",
        "            vocab, inp, target = prepare_data(X_Train, Y_Train, n_instance, n_gram_size, n_feature, dsl_groups_ABC)\n",
        "            print('Training Phase..')\n",
        "            hidden_size = 32\n",
        "            input_size = len(vocab) # Number of grams in vocabulary\n",
        "            n_layers = 1 # Number of layers of RNN\n",
        "            embedding_size = 32\n",
        "            lr = 0.001\n",
        "            batch = 32\n",
        "            n_epochs = 1000\n",
        "            model, losses = start_training(inp, target, input_size, hidden_size, n_layers, embedding_size, lr, batch, n_epochs)\n",
        "            models.append(model)\n",
        "            all_losses.append(losses)\n",
        "\n",
        "            x_test, y_test = get_data_chunk(X_Test, Y_Test, n_instance, dsl_groups_ABC)\n",
        "            all_accuracies.append(test_model(model, x_test, y_test, n_gram_size, vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Making n-grams at 0m 0s .. of size:  7\n",
            "Extracting 7 features at 0m 0s ...\n",
            "Creating Encoding for X\n",
            "100% data prepared at time 0m 6s \n",
            "Creating Encoding for Y\n",
            "Training Phase..\n",
            " ####################  100.0 % [0m 36s epoch: 1000 loss: 9.0843] \n",
            "Training Complete.\n",
            "Making n-grams for Test Data of size:  7 at 0m 0s ..\n",
            "Preparing encoding for Test Data at 0m 0s\n",
            "Creating Encoding for X\n",
            "100% data prepared at time 0m 43s \n",
            "Creating Encoding for Y\n",
            "Encoding completed at 0m 6s\n",
            "Accuracy is 63.878326416015625%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Making n-grams at 0m 0s .. of size:  8\n",
            "Extracting 7 features at 0m 0s ...\n",
            "Creating Encoding for X\n",
            "50.0% data prepared at time 0m 3s "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-142-3bc72b415d83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn_gram_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn_gram_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_gram_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsl_groups_ABC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Phase..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-141-8ff930bad50a>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(X, Y, n_samples, n_gram_size, n_features, lang_keys)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mword_to_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_encodings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_grams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-132-318ca9de6d72>\u001b[0m in \u001b[0;36mcreate_encodings\u001b[0;34m(X_grams, Y, word_to_ix)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mgramlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_grams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# list of ngrams in example j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mgramlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgramlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgramlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mgrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgramlist\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# resulting grams list must not be empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-132-318ca9de6d72>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mgramlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_grams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# list of ngrams in example j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mgramlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgramlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgramlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mgrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgramlist\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# resulting grams list must not be empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}